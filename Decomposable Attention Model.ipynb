{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attention_trail.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "kgaaydXoGrEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJhO2zFNUXk9",
        "outputId": "0e8950c6-c880-4c5a-8847-4fdf233c3ff5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2tvMYSEF5a4",
        "outputId": "6ec06251-7e43-44eb-a155-0f751816dd9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "import re \n",
        "import os\n",
        "import keras\n",
        "import numpy as np\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model\n",
        "from keras.layers import  Lambda, Input, Dense, GlobalAveragePooling1D, GlobalMaxPooling1D,Reshape, \\\n",
        "Activation, SimpleRNN,GRU, Bidirectional, LSTM, dot, concatenate, Dropout,Conv2D, MaxPooling2D, Flatten\n",
        "from keras.layers.embeddings import Embedding\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Sequential\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load processed data"
      ],
      "metadata": {
        "id": "NoPa-HD5KDXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Snli_project/tokenization_data.pickle', 'rb') as f:\n",
        "    loaded_data = pickle.load(f)  \n",
        "\n",
        "tokenizer = Tokenizer(char_level=False)\n",
        "tokenizer.fit_on_texts(loaded_data)\n",
        "max_length = 25\n",
        "vocab_size = len(tokenizer.word_index)"
      ],
      "metadata": {
        "id": "kyPeTe9bTMH7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Snli_project/train_data.pickle', 'rb') as f:\n",
        "  preproc_premise, preproc_hypothesis, Y_train = pickle.load(f)\n",
        "\n",
        "with open('/content/drive/MyDrive/Snli_project/test_data.pickle', 'rb') as f:\n",
        "  preproc_premise_T, preproc_hypothesis_T, Y_test = pickle.load(f)         "
      ],
      "metadata": {
        "id": "AUg6VKMJI42R"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(Y_train), len(preproc_premise))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzg9dtMaxCZo",
        "outputId": "a0557bc5-1ea2-48ae-8d13-da7bb4c9a4b9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "559203 559203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Glove"
      ],
      "metadata": {
        "id": "6M0eV7EWXgj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 300\n",
        "GLOVE_DIR = '/content/drive/MyDrive/Snli_project/Glove'\n",
        "embeddings_index = {}\n",
        "f = open(os.path.join(GLOVE_DIR, 'glove.6B.300d.txt'))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Found %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "38nVzAAiU0Nn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "152cd5ab-40a0-456f-e7ee-fc7dc45edccc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "oov=0\n",
        "embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, EMBEDDING_DIM))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    else:\n",
        "      std = 1.0\n",
        "      mean = 0.0\n",
        "      embedding_matrix[i] = std * np.random.randn(300) + mean\n",
        "      oov +=1\n",
        "print(oov)        "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mr2S-js7jBvu",
        "outputId": "605ae708-e1e9-48bb-dccb-83ecb9e3db6b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Equations"
      ],
      "metadata": {
        "id": "mUv8mdIxf80R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# a = np.arange(0.0, 30.0, 1.0).reshape(2, 3, 5)\n",
        "# b = np.arange(20.0, 50.0, 1.0).reshape(2, 3, 5)\n",
        "# aTb = keras.layers.Dot(axes=(2, 2))([a, b])\n",
        "# print(aTb)\n",
        "# aTb_T = tf.linalg.matrix_transpose(aTb)\n",
        "# print(aTb_T)\n",
        "# segma_col = K.sum(aTb , axis=1)\n",
        "# segma_col = Reshape(( 3,-1), input_shape=segma_row.shape)(segma_col)\n",
        "\n",
        "# alpha_summation = tf.divide(aTb_T, segma_col)\n",
        "# alpha = keras.layers.Dot(axes=(2, 1))([alpha_summation, a])\n",
        "\n",
        "# # print(aTb)\n",
        "# # print(beta_summation)\n",
        "# # print(beta)"
      ],
      "metadata": {
        "id": "1rKxXiaBDU__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a = np.arange(0.0, 30.0, 1.0).reshape(2, 3, 5)\n",
        "# b = np.arange(20.0, 50.0, 1.0).reshape(2, 3, 5)\n",
        "# aTb = keras.layers.Dot(axes=(2, 2))([a, b])\n",
        "\n",
        "# segma_row = K.sum(aTb , axis=2)\n",
        "# segma_row = Reshape(( 3,-1), input_shape=segma_row.shape)(segma_row)\n",
        "# beta_summation = tf.divide(aTb, segma_row)\n",
        "# beta = keras.layers.Dot(axes=(2, 1))([beta_summation, b])\n",
        "\n",
        "# v = concatenate([a[:,0], b[:,0]])\n",
        "# print(a)\n",
        "# print('____________________')\n",
        "# print(b)\n",
        "# print('_____________________')\n",
        "# print(v)\n",
        "# print('_____________________')\n",
        "# print(a[:,0])\n"
      ],
      "metadata": {
        "id": "6Z6maUcl5hL9"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "3jItNAU4cyRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "EMBEDDING_DIM = 300\n",
        "def get_model():\n",
        "\n",
        "    inp1 = Input((max_length,))\n",
        "    inp2 = Input((max_length,))\n",
        "    \n",
        "    a = Embedding(vocab_size+1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
        "                                  input_length=max_length, trainable=False, mask_zero=True)(inp1)\n",
        "    b = Embedding(vocab_size+1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
        "                                  input_length=max_length, trainable=False, mask_zero=True)(inp2)\n",
        "\n",
        "    a = tf.math.l2_normalize(x=a, axis = 2)\n",
        "    b = tf.math.l2_normalize(x=b, axis = 2)\n",
        "    a = Dense(200)(a)\n",
        "    a = Dropout(0.2)(a)\n",
        "    b = Dense(200)(b) \n",
        "    b = Dropout(0.2)(b)                                  \n",
        "    #************************************** Attend ***********************************\n",
        "    aTb = keras.layers.Dot(axes=(2, 2))([a, b])\n",
        "    exp_aTb = tf.math.exp(aTb)\n",
        "    exp_aTb_T = tf.linalg.matrix_transpose(aTb)\n",
        "\n",
        "    segma_row = K.sum(exp_aTb, axis=2)\n",
        "    segma_row = Reshape(( max_length,-1), input_shape=segma_row.shape)(segma_row)\n",
        "    beta_summation = tf.divide(exp_aTb, segma_row)\n",
        "    beta = keras.layers.Dot(axes=(2, 1), name='beta')([beta_summation, b])\n",
        "\n",
        "    segma_col = K.sum(exp_aTb, axis=1)\n",
        "    segma_col = Reshape(( max_length,-1), input_shape = segma_col.shape)(segma_col)\n",
        "    alpha_summation = tf.divide(exp_aTb_T, segma_col)\n",
        "    alpha = keras.layers.Dot(axes=(2, 1), name='alpha')([alpha_summation, a])\n",
        "      \n",
        "    # ****************************** compare *******************************************\n",
        "    v1_i = concatenate([a, beta])\n",
        "    v2_j = concatenate([b, alpha])\n",
        "    G1 = Dense(128, activation=\"relu\", name='G1')(v1_i) \n",
        "    G1 = Dropout(0.2)(G1)\n",
        "    G2 = Dense(128, activation=\"relu\", name='G2')(v2_j)\n",
        "    G2 = Dropout(0.2)(G2) \n",
        "    #******************************** Aggregate *****************************************                       \n",
        "    v1 = Lambda(lambda x: K.sum(x , axis=1))(G1)\n",
        "    v2 = Lambda(lambda x: K.sum(x , axis=1))(G2)\n",
        "\n",
        "    v = concatenate([v1, v2])\n",
        "    H = Dense(128, activation=\"relu\", name='H')(v)\n",
        "    H = Dropout(0.2)(H) \n",
        "    outp = Dense(3, activation=\"softmax\", name=\"final_output\")(H)\n",
        "    \n",
        "    model = Model(inputs=[inp1,inp2], outputs=outp)\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  # optimizer = Adam(learning_rate= 0.001),\n",
        "                  optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.05,\n",
        "                                              initial_accumulator_value=0.1,\n",
        "                                              epsilon=1e-07),\n",
        "                  metrics=['accuracy'],  \n",
        "                 )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "lWKuh9qSdPcd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uwgFizbdun2",
        "outputId": "0a36fcbf-dd62-4738-f8ba-1796fbc1da6a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, 25)]         0           []                               \n",
            "                                                                                                  \n",
            " input_6 (InputLayer)           [(None, 25)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding_4 (Embedding)        (None, 25, 300)      10083000    ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_5 (Embedding)        (None, 25, 300)      10083000    ['input_6[0][0]']                \n",
            "                                                                                                  \n",
            " tf.math.l2_normalize_4 (TFOpLa  (None, 25, 300)     0           ['embedding_4[0][0]']            \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.math.l2_normalize_5 (TFOpLa  (None, 25, 300)     0           ['embedding_5[0][0]']            \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 25, 200)      60200       ['tf.math.l2_normalize_4[0][0]'] \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 25, 200)      60200       ['tf.math.l2_normalize_5[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 25, 200)      0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 25, 200)      0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dot (Dot)                      (None, 25, 25)       0           ['dropout_1[0][0]',              \n",
            "                                                                  'dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " tf.math.exp (TFOpLambda)       (None, 25, 25)       0           ['dot[0][0]']                    \n",
            "                                                                                                  \n",
            " tf.math.reduce_sum (TFOpLambda  (None, 25)          0           ['tf.math.exp[0][0]']            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.math.reduce_sum_1 (TFOpLamb  (None, 25)          0           ['tf.math.exp[0][0]']            \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " reshape (Reshape)              (None, 25, 1)        0           ['tf.math.reduce_sum[0][0]']     \n",
            "                                                                                                  \n",
            " tf.linalg.matrix_transpose (TF  (None, 25, 25)      0           ['dot[0][0]']                    \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)            (None, 25, 1)        0           ['tf.math.reduce_sum_1[0][0]']   \n",
            "                                                                                                  \n",
            " tf.math.truediv (TFOpLambda)   (None, 25, 25)       0           ['tf.math.exp[0][0]',            \n",
            "                                                                  'reshape[0][0]']                \n",
            "                                                                                                  \n",
            " tf.math.truediv_1 (TFOpLambda)  (None, 25, 25)      0           ['tf.linalg.matrix_transpose[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'reshape_1[0][0]']              \n",
            "                                                                                                  \n",
            " beta (Dot)                     (None, 25, 200)      0           ['tf.math.truediv[0][0]',        \n",
            "                                                                  'dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " alpha (Dot)                    (None, 25, 200)      0           ['tf.math.truediv_1[0][0]',      \n",
            "                                                                  'dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 25, 400)      0           ['dropout_1[0][0]',              \n",
            "                                                                  'beta[0][0]']                   \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 25, 400)      0           ['dropout_2[0][0]',              \n",
            "                                                                  'alpha[0][0]']                  \n",
            "                                                                                                  \n",
            " G1 (Dense)                     (None, 25, 128)      51328       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " G2 (Dense)                     (None, 25, 128)      51328       ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 25, 128)      0           ['G1[0][0]']                     \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 25, 128)      0           ['G2[0][0]']                     \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 128)          0           ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 128)          0           ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 256)          0           ['lambda[0][0]',                 \n",
            "                                                                  'lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " H (Dense)                      (None, 128)          32896       ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 128)          0           ['H[0][0]']                      \n",
            "                                                                                                  \n",
            " final_output (Dense)           (None, 3)            387         ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 20,422,339\n",
            "Trainable params: 256,339\n",
            "Non-trainable params: 20,166,000\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=1, \n",
        "#                                             verbose=1, factor=0.1, min_lr=0.0001)\n",
        "early = EarlyStopping(monitor=\"val_accuracy\", mode=\"max\", patience=3)\n",
        "model_callbacks = [early]\n",
        "\n",
        "model_history = model.fit([preproc_premise, preproc_hypothesis],Y_train,\n",
        "                                  batch_size=4, \n",
        "                                  epochs=40,\n",
        "                                  validation_split = 0.2,\n",
        "                                  callbacks = model_callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8gtAi8SSCPG",
        "outputId": "47de339f-e54e-4800-e222-b3f975178ed8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            " 30882/111841 [=======>......................] - ETA: 17:37 - loss: 0.9046 - accuracy: 0.5776"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/Snli_project/models/Attention_model.h5\")"
      ],
      "metadata": {
        "id": "adTQEJmNeVOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import numpy as np\n",
        "test_pred = model.predict([preproc_premise_T, preproc_hypothesis_T], batch_size=128)\n",
        "i = 0\n",
        "for x,y in zip(np.argmax(test_pred, axis=1), np.argmax(Y_test, axis=1)):\n",
        "    if x == y:\n",
        "        i += 1\n",
        "test_acc = i/Y_test.shape[0] * 100\n",
        "print(\"Accuracy on test set is: %\"+str(test_acc))"
      ],
      "metadata": {
        "id": "uGP4tiapk72j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def eval_metric(model, history, metric_name,model_nam):\n",
        "\n",
        "    metric = history.history[metric_name]\n",
        "    val_metric = history.history['val_' + metric_name]\n",
        "    e = range(1, NB_START_EPOCHS + 1)\n",
        "    plt.plot(e, metric, 'bo', label='Train ' + metric_name)\n",
        "    plt.plot(e, val_metric, 'b', label='Validation ' + metric_name)\n",
        "    plt.xlabel('Epoch number')\n",
        "    plt.ylabel(metric_name)\n",
        "    plt.title('Comparing training and validation ' + metric_name+' ' +model_nam)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def optimal_epoch(model_hist):\n",
        "    min_epoch = np.argmin(model_hist.history['val_loss']) + 1\n",
        "    print(\"Minimum validation loss reached in epoch {}\".format(min_epoch))\n",
        "    return min_epoch     "
      ],
      "metadata": {
        "id": "NzrSsiNOk0jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NB_START_EPOCHS = 5\n",
        "reduced_min = optimal_epoch(model_history)\n",
        "eval_metric(model, model_history, 'accuracy', 'Reduced_USE_Embedding+6BiLSTM')"
      ],
      "metadata": {
        "id": "rbCkQqnek3sX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4_yU8q7Ql7jZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}